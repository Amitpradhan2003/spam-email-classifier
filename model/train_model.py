import pandas as pd
import joblib
import nltk

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Download once (safe)
nltk.download("stopwords")

df = pd.read_csv(
    r"C:\Users\ap505\OneDrive\Desktop\Spam_detection\data\combined_data.csv",
    encoding="latin-1"
)

# Ensure correct columns
df = df[["label", "message"]]
df["label"] = df["label"].astype(int)

print("Dataset size:", df.shape)
print("Label distribution:\n", df["label"].value_counts())


X_train, X_test, y_train, y_test = train_test_split(
    df["message"],
    df["label"],
    test_size=0.2,
    random_state=42,
    stratify=df["label"]
)

# Vectorization
vectorizer = TfidfVectorizer(
    stop_words="english",
    max_features=5000
)

X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train Model
model = MultinomialNB()
model.fit(X_train_vec, y_train)

# Evaluation
y_pred = model.predict(X_test_vec)

print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred, target_names=["Ham", "Spam"]))

# Save Model
joblib.dump(model, "spam_model.pkl")
joblib.dump(vectorizer, "vectorizer.pkl")

print("\nâœ… Model and vectorizer saved successfully")
